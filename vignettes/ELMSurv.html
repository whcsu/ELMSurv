<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Hong Wang, Jianxin Wang and Lifeng Zhou" />

<meta name="date" content="2017-09-01" />

<title>A Survival Ensemble of Extreme Learning Machine</title>






<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">A Survival Ensemble of Extreme Learning Machine</h1>
<h4 class="author"><em>Hong Wang, Jianxin Wang and Lifeng Zhou</em></h4>
<h4 class="date"><em>2017-09-01</em></h4>



<p>Due to the fast learning speed, simplicity of implementation and minimal human intervention, extreme learning machine has received considerable attentions recently, mostly from the machine learning community. Generally, extreme learning machine and its various variants focus on classification and regression problems. Its potential application in analyzing censored time-to-event data is yet to be verified. In this study, we present an extreme learning machine ensemble to model right-censored survival data by combining the Buckley-James transformation and the random forest framework. According to experimental and statistical analysis results, we show that the proposed model outperforms popular survival models such as random survival forest, Cox proportional hazard models on well-known low-dimensional and high-dimensional benchmark datasets in terms of both prediction accuracy and time efficiency.</p>
<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>In this article, we want to explore the plausibility of extending the extreme learning machine (ELM), an emerging fast classification and regression learning algorithm for single-hidden layer feedforward neural networks (SLFN), to analysis of right-censored survival data. The main concept behind the ELM is the replacement of a computation-intensive procedure of finding the input weights and bias values of the hidden layer by just random initializations. The subsequent output weights of the network can be calculated analytically and efficiently using a least square approach and this usually implies a fast model training speed. Given enough hidden neurons, ELM is proven to be a universal function approximator.</p>
</div>
<div id="major-concerns" class="section level2">
<h2>Major concerns</h2>
<p>Before applying ELM to censored survival data, two vital issues have to be properly addressed. First, ELM itself does not handle censored survival times and simple exclusion of censored observations from training data will result in significant biases in event predictions. Second, ELM is somewhat sensitive to random initialization of input-layer weights and hidden-layer biases, and this might will incur unstable predictions. In this research, we deal with the first issue by replacing the survival times of censored observations with surrogate values using the Buckley-James estimator, which is a censoring unbiased transformation in nature. For the second issue, we will adopt a well-established random forest ensemble learning framework which is most effective when the base learner is unstable. In our approach, the base learners in the original random forest is changed from decision trees to ELM neural networks.</p>
</div>
<div id="the-buckley-james-estimator" class="section level2">
<h2>The Buckley-James Estimator</h2>
Suppose that we have a training data <span class="math inline">\(D\)</span> of <span class="math inline">\(n\)</span> observations and sample covariates <span class="math inline">\({\mathbf x}\)</span> are <span class="math inline">\(p\)</span>-dimensional vectors namely, <span class="math inline">\({\mathbf x}_i=(x_{i1},x_{i2},\cdots, x_{ip}), i \in 1,2,\cdots, n\)</span>. The Buckley-James estimator assumes that the transformed survival time ( e.g. a monotone transformation such as the logarithm transform) <span class="math inline">\(T_i\)</span> follows a linear regression
<span class="math display">\[\begin{equation} \label{bj1}
T_i=\alpha+{\mathbf x}_i \beta+\epsilon_i,    \ \ \ \ i=1,\cdots, n
\end{equation}\]</span>
<p>where <span class="math inline">\(\epsilon_i\)</span> is the i.i.d error term with <span class="math inline">\(E(\epsilon_i)=0\)</span> and <span class="math inline">\(Var(\epsilon_i) =\sigma^2\)</span>. For simplicity, we can absorb the unknown intercept <span class="math inline">\(\alpha\)</span> into <span class="math inline">\(\epsilon_i\)</span> and a new term would be <span class="math inline">\(\xi_i=\alpha+\epsilon_i\)</span>. Consequently, the above model could be reformulated as</p>
<span class="math display">\[\begin{equation} \label{bj2}
T_i={\mathbf x}_i \beta+\xi_i,    \ \ \ \ i=1,\cdots, n
\end{equation}\]</span>
If there were no censoring, parameters of the above model could be estimated via an ordinary least square approach or its regularized extensions. However, in many cases, only censored observations from <span class="math inline">\(Y\)</span> are available. In the case of right-censored data, we can only observe <span class="math inline">\((Y_i,\delta_i, {\mathbf x_i})\)</span>, where <span class="math inline">\(Y_i=min(T_i, C_i)\)</span>, <span class="math inline">\(C_i\)</span> is the transformed censoring time and $_i=I(T_iC_i) $, the censoring indicator. And, in the presence of censoring, the usual least square approach is not applicable. Buckley and James proposed to approximate those censored survival times by their conditional expectations and define the newly imputed survival times as
<span class="math display">\[\begin{equation}
Y_i^*=Y_i \delta_i+E(T_i|T_i&gt;Y_i,{\mathbf x_i})(1-\delta_i),  \ \ \ \ i=1,\cdots, n
\end{equation}\]</span>
<p>For uncensored observations, <span class="math inline">\(\delta_i=1\)</span> and <span class="math inline">\(Y_i^*=T_i\)</span>; for censored observations, <span class="math inline">\(\delta_i=0\)</span> and <span class="math inline">\(Y_i^*=E(T_i|T_i&gt;Y_i,{\mathbf x_i})\)</span>. Hence, it is easy to verify that <span class="math inline">\(E(Y_i^*)=E(T_i)\)</span>. The Buckley-James estimator calculates the conditional expectation given the censored survival time and the corresponding covariates by</p>
<span class="math display">\[\begin{eqnarray}
E(T_i|T_i&gt;Y_i,{\mathbf x_i})&amp;=&amp; E({\mathbf x_i} \beta+\xi_i|{\mathbf x_i} \beta+\xi_i&gt;Y_i)\nonumber \\
&amp;=&amp; {\mathbf x_i} \beta+E(\xi_i|{\mathbf x_i} \beta+\xi_i&gt;Y_i)  \nonumber \\
&amp;=&amp; {\mathbf x_i} \beta+E(\xi_i|\xi_i&gt;Y_i-{\mathbf x_i} \beta)  \nonumber \\
&amp;=&amp; {\mathbf x_i} \beta+\int_{Y_i-{\mathbf x_i} \beta}^{\infty} \frac{\xi dF(\xi)}{1-F(Y_i-{\mathbf x_i}\beta)}
\end{eqnarray}\]</span>
where <span class="math inline">\(F(\xi)\)</span> is an estimator of the distribution function (e.g. the Kaplan-Meier estimator <span class="math inline">\(\hat F\)</span> ) of <span class="math inline">\(\xi\)</span>. Then, we have
<span class="math display">\[\begin{equation}\label{ystar}
Y_i^*=Y_i \delta_i+ (1-\delta_i) \bigg({\mathbf x_i}\beta+\frac{\sum\limits_{\xi_j&gt;\xi_i}s_j \xi_j}{1-F(\xi_i)},    \bigg), \ \ \ \ i=1,\cdots, n
\end{equation}\]</span>
<p>where <span class="math inline">\(s_j\)</span> are steps of the estimated function <span class="math inline">\(\hat F\)</span>. The unknown coefficients <span class="math inline">\(\beta\)</span> in the above equation can be computed through a straightforward iterative procedure. And in case of a high dimensional <span class="math inline">\(p\)</span>, a regularized technique with the elastic net penalty proposed in can be adopted.</p>
</div>
<div id="survival-ensemble-of-elm" class="section level2">
<h2>Survival Ensemble of ELM</h2>
<p>As is known, the success of an ensemble method lies in the diversity among all the base learners, thus in the proposed method, the most popular methods to achieve diversity from data such as bagging and random subspace are applied. More diversity is introduced through imputation of the censored observations via the Buckley-James estimator. In our approach, only a subset of covariates are considered in estimating the censored survival times for each base kernel ELM. The fact that different estimates might be made to the same censored training sample actually diversify the training data. In fact, according to the study of the DEcoratE (Diverse Ensemble Creation by Oppositional Relabeling of Artificial Training Examples) algorithm, a small portion of artificially generated wrong observations would generate a more diverse ensemble. In this sense, even wrong predictions occasionally made by the Buckley-James estimator could improve the ensemble’s performance.</p>
<p>The pseudo-code of the proposed survival ensemble of extreme learning machine (SE-ELM) algorithm and more details can be found in <span class="citation">(H. Wang, Wang, and Zhou 2018)</span>:</p>
</div>
<div id="examples" class="section level2">
<h2>Examples</h2>
<p>Survival Ensemble of ELM with default settings</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-wangwangzhou2017">
<p>Wang, Hong, Jianxin Wang, and Lifeng Zhou. 2018. “A Survival Ensemble of Extreme Learning Machine.” <em>Applied Intelligence</em> 49 (January). Springer: 1–25.</p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
